{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75f862a1-0e70-4733-b8f0-bae0568fbd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] preprocess_shared loaded.\n"
     ]
    }
   ],
   "source": [
    "# preprocess_shared.ipynb\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyxdf\n",
    "from dataclasses import dataclass\n",
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "# -------------------------\n",
    "# Config\n",
    "# -------------------------\n",
    "@dataclass\n",
    "class PreprocConfig:\n",
    "    # XDF search roots\n",
    "    xdf_root_cf: str\n",
    "    xdf_root_sd: str\n",
    "\n",
    "    # Streams\n",
    "    emg_stream_name: str = \"EMG\"\n",
    "    com_stream_name: str = \"CenterOfMass1\"\n",
    "    video_stream_names: tuple = (\"video data\", \"video_data\")\n",
    "\n",
    "    # Kinematics (optional)\n",
    "    kin_stream_name: str = \"LinearSegmentKinematicsDatagram1\"\n",
    "    include_kin_acc_features: bool = True   # keeps backward compatibility\n",
    "    kin_segments: tuple = (1, 5, 7)          # Pelvis=1, T8=5, Head=7 (MATLAB indexing)\n",
    "    kin_strict: bool = True                 # if True, raise when kinematics stream is missing\n",
    "\n",
    "    # Resampling\n",
    "    target_fs: float = 50.0\n",
    "    min_trial_duration_sec: float = 5.0\n",
    "\n",
    "    # EMG envelope\n",
    "    emg_bandpass_hz: tuple = (10.0, 400.0)\n",
    "    emg_envelope_lp_hz: float = 8.0\n",
    "\n",
    "    # MoS outlier filtering\n",
    "    b_cm_abs_thresh: float = 100.0\n",
    "    outlier_ratio_max: float = 0.1\n",
    "\n",
    "    # Misstep event tolerance band\n",
    "    event_tol_pre_sec: float = 0.05\n",
    "    event_tol_post_sec: float = 0.10\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# General helpers\n",
    "# -------------------------\n",
    "def normalize_trial_name(name: str) -> str:\n",
    "    s = str(name).strip()\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    if not s.lower().endswith(\".xdf\"):\n",
    "        s += \".xdf\"\n",
    "    return s\n",
    "\n",
    "def find_xdf_path(trial_xdf: str, cfg: PreprocConfig) -> str:\n",
    "    p1 = os.path.join(cfg.xdf_root_cf, trial_xdf)\n",
    "    if os.path.exists(p1):\n",
    "        return p1\n",
    "    p2 = os.path.join(cfg.xdf_root_sd, trial_xdf)\n",
    "    if os.path.exists(p2):\n",
    "        return p2\n",
    "    return \"\"\n",
    "\n",
    "def estimate_fs(ts: np.ndarray) -> float:\n",
    "    ts = np.asarray(ts, dtype=float)\n",
    "    dt = np.diff(ts)\n",
    "    dt = dt[dt > 0]\n",
    "    if len(dt) == 0:\n",
    "        return np.nan\n",
    "    return 1.0 / np.median(dt)\n",
    "\n",
    "def parse_float_from_cell(x):\n",
    "    if x is None or (isinstance(x, float) and np.isnan(x)):\n",
    "        return np.nan\n",
    "    if isinstance(x, (int, float, np.integer, np.floating)):\n",
    "        return float(x)\n",
    "    s = str(x).strip()\n",
    "    if not s:\n",
    "        return np.nan\n",
    "    try:\n",
    "        return float(s)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def parse_type_from_cell(x):\n",
    "    if x is None or (isinstance(x, float) and np.isnan(x)):\n",
    "        return \"UNK\"\n",
    "    s = str(x).strip().upper()\n",
    "    if s in (\"F\", \"B\", \"FB\"):\n",
    "        return s\n",
    "    if s == \"\":\n",
    "        return \"UNK\"\n",
    "    return s\n",
    "\n",
    "# -------------------------\n",
    "# Stream loaders\n",
    "# -------------------------\n",
    "def load_stream_df(xdf_path: str, stream_name: str, col_prefix: str) -> pd.DataFrame | None:\n",
    "    streams, _ = pyxdf.load_xdf(xdf_path)\n",
    "    target = None\n",
    "    for s in streams:\n",
    "        if s[\"info\"][\"name\"][0] == stream_name:\n",
    "            target = s\n",
    "            break\n",
    "    if target is None:\n",
    "        return None\n",
    "\n",
    "    ts = np.asarray(target[\"time_stamps\"], dtype=float)\n",
    "    data = np.asarray(target[\"time_series\"])\n",
    "    if data.ndim == 1:\n",
    "        data = data.reshape(-1, 1)\n",
    "\n",
    "    df = pd.DataFrame(data, columns=[f\"{col_prefix}{i+1}\" for i in range(data.shape[1])])\n",
    "    df[\"timestamp\"] = ts\n",
    "    df = df.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def _kin_col_name(col_prefix: str, one_based_idx: int) -> str:\n",
    "    return f\"{col_prefix}{one_based_idx}\"\n",
    "\n",
    "def compute_kin_acc_mag_df(kin_df: pd.DataFrame, cfg: PreprocConfig, col_prefix: str = \"KIN_ch\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute acceleration magnitude for selected segments from a kinematics stream that follows\n",
    "    the MATLAB convention of 9 values per segment (pos[1:3], vel[4:6], acc[7:9]) across 23 segments.\n",
    "\n",
    "    Expects columns like: KIN_ch1..KIN_ch207 plus 'timestamp'.\n",
    "    Returns DataFrame with 'timestamp' and columns:\n",
    "      kin_acc_mag_seg{segIdx} (one per cfg.kin_segments)\n",
    "    \"\"\"\n",
    "    if kin_df is None or len(kin_df) == 0:\n",
    "        return None\n",
    "\n",
    "    ts = kin_df[\"timestamp\"].values.astype(float)\n",
    "    out = {\"timestamp\": ts}\n",
    "\n",
    "    # Ensure we have the expected columns; if not, we will still try gracefully.\n",
    "    for seg_idx in cfg.kin_segments:\n",
    "        base = (int(seg_idx) - 1) * 9  # 0-based offset in MATLAB rows\n",
    "        ax_col = _kin_col_name(col_prefix, base + 7)\n",
    "        ay_col = _kin_col_name(col_prefix, base + 8)\n",
    "        az_col = _kin_col_name(col_prefix, base + 9)\n",
    "\n",
    "        if ax_col not in kin_df.columns or ay_col not in kin_df.columns or az_col not in kin_df.columns:\n",
    "            # missing expected channels -> produce NaNs so downstream interpolation works\n",
    "            out[f\"kin_acc_mag_seg{seg_idx}\"] = np.full_like(ts, np.nan, dtype=float)\n",
    "            continue\n",
    "\n",
    "        ax = kin_df[ax_col].values.astype(float)\n",
    "        ay = kin_df[ay_col].values.astype(float)\n",
    "        az = kin_df[az_col].values.astype(float)\n",
    "        out[f\"kin_acc_mag_seg{seg_idx}\"] = np.sqrt(ax*ax + ay*ay + az*az)\n",
    "\n",
    "    return pd.DataFrame(out).sort_values(\"timestamp\").reset_index(drop=True)\n",
    "\n",
    "\n",
    "def load_kin_df(xdf_path: str, cfg: PreprocConfig) -> pd.DataFrame | None:\n",
    "    \"\"\"Convenience loader for the kinematics stream.\"\"\"\n",
    "    return load_stream_df(xdf_path, cfg.kin_stream_name, col_prefix=\"KIN_ch\")\n",
    "\n",
    "\n",
    "\n",
    "def clean_emg_envelope(df_emg: pd.DataFrame, cfg: PreprocConfig) -> pd.DataFrame:\n",
    "    df = df_emg.copy()\n",
    "    ts = df[\"timestamp\"].values.astype(float)\n",
    "    fs = estimate_fs(ts)\n",
    "    if not np.isfinite(fs) or fs <= 0:\n",
    "        return df\n",
    "\n",
    "    nyq = 0.5 * fs\n",
    "    low_hz, high_hz = cfg.emg_bandpass_hz\n",
    "    low = max(low_hz / nyq, 0.001)\n",
    "    high = min(high_hz / nyq, 0.99)\n",
    "\n",
    "    if high > low:\n",
    "        b_bp, a_bp = butter(2, [low, high], btype=\"band\")\n",
    "    else:\n",
    "        b_bp, a_bp = butter(2, low, btype=\"high\")\n",
    "\n",
    "    wn = min(max(cfg.emg_envelope_lp_hz / nyq, 0.001), 0.99)\n",
    "    b_lp, a_lp = butter(4, wn, btype=\"low\")\n",
    "\n",
    "    emg_cols = [c for c in df.columns if c.startswith(\"EMG_ch\")]\n",
    "    for c in emg_cols:\n",
    "        sig = df[c].values.astype(float)\n",
    "        # guard filtfilt against NaNs\n",
    "        if not np.isfinite(sig).all():\n",
    "            sig = pd.Series(sig).interpolate(limit_direction=\"both\").values\n",
    "        try:\n",
    "            sig_f = filtfilt(b_bp, a_bp, sig)\n",
    "            sig_r = np.abs(sig_f)\n",
    "            sig_e = filtfilt(b_lp, a_lp, sig_r)\n",
    "            df[c] = sig_e.astype(np.float32)\n",
    "        except Exception:\n",
    "            df[c] = sig.astype(np.float32)\n",
    "\n",
    "    return df\n",
    "\n",
    "def load_video_df(xdf_path: str, cfg: PreprocConfig) -> pd.DataFrame | None:\n",
    "    streams, _ = pyxdf.load_xdf(xdf_path)\n",
    "    video = None\n",
    "    for s in streams:\n",
    "        nm = s[\"info\"][\"name\"][0]\n",
    "        if nm in cfg.video_stream_names:\n",
    "            video = s\n",
    "            break\n",
    "    if video is None:\n",
    "        return None\n",
    "\n",
    "    ts = np.asarray(video[\"time_stamps\"], dtype=float)\n",
    "    data = np.asarray(video[\"time_series\"])\n",
    "\n",
    "    if data.ndim == 1:\n",
    "        frame = data.astype(float)\n",
    "        t_video_s = ts - ts[0]\n",
    "    else:\n",
    "        frame = data[:, 0].astype(float)\n",
    "        if data.shape[1] >= 2:\n",
    "            raw_sec = data[:, 1]\n",
    "            t_video_s = np.array([float(str(x).split()[0]) for x in raw_sec], dtype=float)\n",
    "        else:\n",
    "            t_video_s = ts - ts[0]\n",
    "\n",
    "    df = pd.DataFrame({\"timestamp\": ts, \"frame\": frame, \"t_video_s\": t_video_s})\n",
    "    df = df.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "# -------------------------\n",
    "# MoS loaders + filters\n",
    "# -------------------------\n",
    "def compute_keep_files(b_csv_path: str, cfg: PreprocConfig) -> set:\n",
    "    df = pd.read_csv(b_csv_path)\n",
    "    if \"file_name\" not in df.columns or \"b_cm\" not in df.columns:\n",
    "        raise ValueError(\"b_csv must contain columns: file_name, b_cm\")\n",
    "\n",
    "    mask = df[\"b_cm\"].abs() > cfg.b_cm_abs_thresh\n",
    "    ratio = mask.groupby(df[\"file_name\"]).mean()\n",
    "    keep = set(ratio[ratio <= cfg.outlier_ratio_max].index.tolist())\n",
    "    return keep\n",
    "\n",
    "def _mos_time_col(df: pd.DataFrame) -> str:\n",
    "    for c in [\"time_s\", \"timestamp\", \"time\"]:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    raise ValueError(\"b_csv must contain one of: time_s / timestamp / time\")\n",
    "\n",
    "def build_mos_dict(b_csv_path: str, trial_keys: list[str], cfg: PreprocConfig) -> dict:\n",
    "    df = pd.read_csv(b_csv_path)\n",
    "    time_col = _mos_time_col(df)\n",
    "    df = df.rename(columns={time_col: \"timestamp\"})\n",
    "\n",
    "    mos_dict = {}\n",
    "    for fname in trial_keys:\n",
    "        sub = df[df[\"file_name\"].astype(str) == str(fname)].copy()\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        # outlier clip for b_cm\n",
    "        sub = sub[sub[\"b_cm\"].abs() <= cfg.b_cm_abs_thresh].copy()\n",
    "        sub = sub.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        keep_cols = [\"timestamp\", \"b_cm\"]\n",
    "        if \"b_m\" in sub.columns:\n",
    "            keep_cols.append(\"b_m\")\n",
    "        sub = sub[keep_cols].copy()\n",
    "\n",
    "        for c in keep_cols:\n",
    "            sub[c] = pd.to_numeric(sub[c], errors=\"coerce\")\n",
    "\n",
    "        sub = sub.dropna(subset=[\"timestamp\", \"b_cm\"]).reset_index(drop=True)\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        mos_dict[fname] = sub\n",
    "\n",
    "    return mos_dict\n",
    "\n",
    "def load_mos_df_for_trial(b_csv_path: str, trial_xdf: str, cfg: PreprocConfig) -> pd.DataFrame | None:\n",
    "    df = pd.read_csv(b_csv_path)\n",
    "    time_col = _mos_time_col(df)\n",
    "\n",
    "    if \"file_name\" not in df.columns or \"b_cm\" not in df.columns:\n",
    "        raise ValueError(\"MoS CSV must include: file_name, b_cm (and optionally b_m)\")\n",
    "\n",
    "    sub = df[df[\"file_name\"].astype(str) == str(trial_xdf)].copy()\n",
    "    if sub.empty:\n",
    "        return None\n",
    "\n",
    "    sub = sub.rename(columns={time_col: \"timestamp\"}).sort_values(\"timestamp\").reset_index(drop=True)\n",
    "\n",
    "    keep_cols = [\"timestamp\", \"b_cm\"]\n",
    "    if \"b_m\" in sub.columns:\n",
    "        keep_cols.append(\"b_m\")\n",
    "    sub = sub[keep_cols].copy()\n",
    "\n",
    "    for c in keep_cols:\n",
    "        sub[c] = pd.to_numeric(sub[c], errors=\"coerce\")\n",
    "    sub = sub.dropna(subset=[\"timestamp\", \"b_cm\"]).reset_index(drop=True)\n",
    "    return sub if not sub.empty else None\n",
    "\n",
    "# -------------------------\n",
    "# Uniform feature construction (used by BOTH builder + inference)\n",
    "# -------------------------\n",
    "def build_uniform_features(mos_df: pd.DataFrame, emg_df: pd.DataFrame, com_df: pd.DataFrame, cfg: PreprocConfig, kin_df: pd.DataFrame | None = None):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      t_uniform (abs time)\n",
    "      feat_df columns: timestamp, b_cm, b_m(optional), EMG_ch*_env, COM_ch*\n",
    "      feature_names list in exact order for model input (excluding timestamp)\n",
    "    \"\"\"\n",
    "    mos_ts = mos_df[\"timestamp\"].values.astype(float)\n",
    "    t0, t1 = float(mos_ts[0]), float(mos_ts[-1])\n",
    "\n",
    "    if (t1 - t0) < cfg.min_trial_duration_sec:\n",
    "        return None, None, None\n",
    "\n",
    "    dt = 1.0 / float(cfg.target_fs)\n",
    "    t_uniform = np.arange(t0, t1, dt)\n",
    "\n",
    "    emg_ts = emg_df[\"timestamp\"].values.astype(float)\n",
    "    com_ts = com_df[\"timestamp\"].values.astype(float)\n",
    "\n",
    "    cols = {\"timestamp\": t_uniform}\n",
    "    feature_names = []\n",
    "\n",
    "    # MoS first\n",
    "    cols[\"b_cm\"] = np.interp(t_uniform, mos_ts, mos_df[\"b_cm\"].values.astype(float))\n",
    "    feature_names.append(\"b_cm\")\n",
    "    if \"b_m\" in mos_df.columns:\n",
    "        cols[\"b_m\"] = np.interp(t_uniform, mos_ts, mos_df[\"b_m\"].values.astype(float))\n",
    "        feature_names.append(\"b_m\")\n",
    "\n",
    "    # EMG channels (assumes emg_df already envelope-filtered)\n",
    "    emg_cols = [c for c in emg_df.columns if c.startswith(\"EMG_ch\")]\n",
    "    for c in emg_cols:\n",
    "        colname = f\"{c}_env\"\n",
    "        cols[colname] = np.interp(t_uniform, emg_ts, emg_df[c].values.astype(float))\n",
    "        feature_names.append(colname)\n",
    "\n",
    "    \n",
    "    # Kinematics accel magnitude (optional; appended AFTER EMG, BEFORE COM to keep old ordering unless enabled)\n",
    "    if getattr(cfg, \"include_kin_acc_features\", False) and (kin_df is not None) and len(kin_df) > 0:\n",
    "        kin_mag_df = compute_kin_acc_mag_df(kin_df, cfg, col_prefix=\"KIN_ch\")\n",
    "        kin_ts = kin_mag_df[\"timestamp\"].values.astype(float)\n",
    "\n",
    "        # Map MATLAB segment indices to friendly names (fixed mapping for (1,5,7))\n",
    "        friendly = {1: \"Pelvis\", 5: \"T8\", 7: \"Head\"}\n",
    "        for seg_idx in cfg.kin_segments:\n",
    "            src_col = f\"kin_acc_mag_seg{int(seg_idx)}\"\n",
    "            name = friendly.get(int(seg_idx), f\"Seg{int(seg_idx)}\")\n",
    "            out_col = f\"ACCmag_{name}\"\n",
    "            cols[out_col] = np.interp(t_uniform, kin_ts, kin_mag_df[src_col].values.astype(float))\n",
    "            feature_names.append(out_col)\n",
    "    elif getattr(cfg, \"include_kin_acc_features\", False) and getattr(cfg, \"kin_strict\", False):\n",
    "        raise RuntimeError(\"Kinematics features enabled (include_kin_acc_features=True) but kin_df is missing/empty.\")\n",
    "\n",
    "    # COM channels\n",
    "    com_cols = [c for c in com_df.columns if c.startswith(\"COM_ch\")]\n",
    "    for c in com_cols:\n",
    "        cols[c] = np.interp(t_uniform, com_ts, com_df[c].values.astype(float))\n",
    "        feature_names.append(c)\n",
    "\n",
    "    feat_df = pd.DataFrame(cols)\n",
    "    return t_uniform, feat_df, feature_names\n",
    "\n",
    "# -------------------------\n",
    "# Missing-data reporting / filling (used by inference; optional elsewhere)\n",
    "# -------------------------\n",
    "def raw_gap_report(df: pd.DataFrame, name: str, top_n: int = 50):\n",
    "    ts = df[\"timestamp\"].values.astype(float)\n",
    "    if len(ts) < 3:\n",
    "        return\n",
    "    dt = np.diff(ts)\n",
    "    med = np.median(dt[dt > 0]) if np.any(dt > 0) else np.nan\n",
    "    if not np.isfinite(med) or med <= 0:\n",
    "        return\n",
    "    gap_idx = np.where(dt > 5 * med)[0]\n",
    "    if len(gap_idx) == 0:\n",
    "        return\n",
    "    print(f\"\\n[RAW GAP] {name}: {len(gap_idx)} gaps (dt > 5x median)\")\n",
    "    for k in gap_idx[:top_n]:\n",
    "        t0, t1 = ts[k], ts[k+1]\n",
    "        print(f\"  gap: {t0:.3f} -> {t1:.3f}  (dt={t1-t0:.3f}s)\")\n",
    "    if len(gap_idx) > top_n:\n",
    "        print(f\"  ... (showing first {top_n})\")\n",
    "\n",
    "def _find_nan_segments(mask: np.ndarray, t: np.ndarray):\n",
    "    mask = mask.astype(bool)\n",
    "    if mask.sum() == 0:\n",
    "        return []\n",
    "    idx = np.where(mask)[0]\n",
    "    segs = []\n",
    "    start = idx[0]\n",
    "    prev = idx[0]\n",
    "    for i in idx[1:]:\n",
    "        if i == prev + 1:\n",
    "            prev = i\n",
    "        else:\n",
    "            segs.append((t[start], t[prev], float(t[prev] - t[start])))\n",
    "            start = i\n",
    "            prev = i\n",
    "    segs.append((t[start], t[prev], float(t[prev] - t[start])))\n",
    "    return segs\n",
    "\n",
    "def fill_short_gaps_per_column(df_feat: pd.DataFrame, time_col: str, max_gap_sec: float, fs: float, print_top_n: int = 50):\n",
    "    t = df_feat[time_col].values.astype(float)\n",
    "    dt = 1.0 / fs\n",
    "    max_gap_samples = int(round(max_gap_sec / dt))\n",
    "\n",
    "    cols = [c for c in df_feat.columns if c != time_col]\n",
    "\n",
    "    print(\"\\n[MISSING CHECK] On uniform grid BEFORE filling:\")\n",
    "    printed = 0\n",
    "    for c in cols:\n",
    "        x = df_feat[c].values\n",
    "        bad = ~np.isfinite(x)\n",
    "        if bad.sum() == 0:\n",
    "            continue\n",
    "        segs = _find_nan_segments(bad, t)\n",
    "        for (ts, te, dur) in segs:\n",
    "            n_samp = int(round((te - ts) / dt)) + 1\n",
    "            print(f\"  {c:14s} NaN: {ts:.3f}->{te:.3f} (~{dur:.3f}s, ~{n_samp} samples)\")\n",
    "            printed += 1\n",
    "            if printed >= print_top_n:\n",
    "                print(f\"  ... (showing first {print_top_n} segments total)\")\n",
    "                break\n",
    "        if printed >= print_top_n:\n",
    "            break\n",
    "\n",
    "    df_filled = df_feat.copy()\n",
    "    for c in cols:\n",
    "        s = pd.Series(df_filled[c].values)\n",
    "        s_interp = s.interpolate(method=\"linear\", limit=max_gap_samples, limit_direction=\"both\")\n",
    "        df_filled[c] = s_interp.values\n",
    "\n",
    "    if not np.isfinite(df_filled[cols].values).all():\n",
    "        print(\"\\n[WARN] NaNs remain after short-gap interpolation (gaps > MAX_GAP_SEC).\")\n",
    "        print(\"       Applying ffill/bfill so output has NO missing values.\")\n",
    "        df_filled[cols] = df_filled[cols].ffill().bfill()\n",
    "\n",
    "    if not np.isfinite(df_filled[cols].values).all():\n",
    "        raise RuntimeError(\"Still found non-finite values after filling.\")\n",
    "\n",
    "    print(\"[OK] All features are finite after filling.\")\n",
    "    return df_filled\n",
    "\n",
    "# -------------------------\n",
    "# Misstep Excel + frame->time mapping (builder use)\n",
    "# -------------------------\n",
    "def load_missteps_from_excel(xlsx_path: str):\n",
    "    df = pd.read_excel(xlsx_path, header=None)\n",
    "    misstep_dict = {}\n",
    "    trial_list = []\n",
    "\n",
    "    for i in range(df.shape[0]):\n",
    "        trial_raw = df.iloc[i, 0]\n",
    "        trial = normalize_trial_name(trial_raw)\n",
    "        if not trial:\n",
    "            continue\n",
    "\n",
    "        events = []\n",
    "        c = 1\n",
    "        while c < df.shape[1]:\n",
    "            frame = parse_float_from_cell(df.iloc[i, c]) if c < df.shape[1] else np.nan\n",
    "            typ = parse_type_from_cell(df.iloc[i, c + 1]) if (c + 1) < df.shape[1] else \"UNK\"\n",
    "            if np.isfinite(frame):\n",
    "                events.append({\"frame\": float(frame), \"type\": typ})\n",
    "            c += 2\n",
    "\n",
    "        if trial not in misstep_dict:\n",
    "            trial_list.append(trial)\n",
    "            misstep_dict[trial] = events\n",
    "        else:\n",
    "            misstep_dict[trial].extend(events)\n",
    "\n",
    "    for k in misstep_dict:\n",
    "        misstep_dict[k] = sorted(misstep_dict[k], key=lambda d: d[\"frame\"])\n",
    "\n",
    "    return misstep_dict, trial_list\n",
    "\n",
    "def map_frames_to_event_intervals(video_df: pd.DataFrame, mos_ts0: float, missteps: list, cfg: PreprocConfig):\n",
    "    vid_frame = video_df[\"frame\"].values.astype(float)\n",
    "    vid_sec = video_df[\"t_video_s\"].values.astype(float)\n",
    "\n",
    "    time_offset = mos_ts0 - vid_sec[0]\n",
    "    vid_sec_aligned = vid_sec + time_offset\n",
    "\n",
    "    intervals = []\n",
    "    for ev in missteps:\n",
    "        f = float(ev[\"frame\"])\n",
    "        typ = ev.get(\"type\", \"UNK\")\n",
    "        idx = int(np.argmin(np.abs(vid_frame - f)))\n",
    "        t_event = float(vid_sec_aligned[idx])\n",
    "        t_start = t_event - float(cfg.event_tol_pre_sec)\n",
    "        t_end   = t_event + float(cfg.event_tol_post_sec)\n",
    "        intervals.append((t_start, t_end, typ))\n",
    "    return intervals\n",
    "\n",
    "print(\"[OK] preprocess_shared loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166ed446-1fe3-41f8-bd74-251ac5fafdc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
